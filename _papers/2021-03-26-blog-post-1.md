---
title: 'Seeing the Un-Scene: Learning Amodal Semantic Maps for Room Navigation'
date: 2021-03-26
permalink: /papers/2021/03/blog-post-4/
tags:
  - GAN
  - Crowd co-creation
---

# Conference
ICCC 2020

# Authors
- Medhini Narasimhan
- Erik Wijmans
- Xinlei Chen
- Trevor Darrell
- Dhruv Batra
- Devi Parikh
- Amanpreet Singh


# Contributions
- Introduced a novel learning-based approach for room
  navigation via a modal prediction of semantic maps.
  The agent learns architectural and stylistic regularities in houses to
  predict regions beyond its field of view.
- Through carefully designed ablations, we show that our model trained to 
  predict semantic maps as intermediate representations achieves better 
  performance on unseen environments compared to a baseline which doesnâ€™t 
  explicitly generate semantic top-down maps.
- To evaluate our approach, we introduce the room navigation task and dataset 
  in the Habitat platform.

# Approach
- Room Navigation Task : Using sensors.
- Room Navigation using Amodal semantic maps :
  Based on general ideas of house designs, Uses Seq2Seq network
- Interesting details :

     - Map generation : ResNet50
    - Point Prediction : ResNet50
    - Point Navigation Policy : ResNeXt
    
# Dataset
- Matterport 3D


  
   
 

