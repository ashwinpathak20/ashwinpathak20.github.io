---
title: 'Exploring Image And Text Modality Datasets For Conversational Summarization'
date: 2021-10-25
permalink: /multimodal/2021/10/blog-post-15/
tags:
- MultiModal
- Vision
- NLP
- Datasets
- MultiModal Summarization
- Survey
---

In this blog we will be exploring and brainstorming on the image and text modality datasets for conversation summarization.

The first step is to list down the requirements and questions for which we are finding the answers :
- What all conversation based Image+Text Datasets are available? How large are they?
- What are their process of generation?
- What scope do we have of this method in our project?
- What all different things can be incorporated to make this process of dataset generation simpler?
- How to get the ground truth summaries?

For Image-Text dataset without conversation, WIT comes out to be a clear winner.

For the Image-Text Conversation Modality, I explored the following datasets :
- Image-Chat
- PhotoChat

## WIT : Wikipedia-Based Image-Text Dataset
- Information : https://ai.googleblog.com/2021/09/announcing-wit-wikipedia-based-image.html
- About the dataset :
  - Text-Image Tuples : 37.6M
  - Unique Images : 11.5M
  - Ref.Text : ~17M
- Process of data collection :
  - Crawl Data
    - Started with content pages
    - Ignored other pages that have discussion, comments, etc:
      - This however is really important for us.
    - Extracted images and texts related to the images.
    - This yields ~150M tuples.
  - Texts were filtered using description sections in wikipedia.
  - Text based filtering 
    - Retained texts of at least length 3
    - Removed generic phrases
    - Alt-text filtering
  - Image & Image-Text based filtering
    - Filtering on image height and width
    - Filtering generic or irrelevant images
    - Retained only licensed images
    - Removed generic image-text pairs
  - Additional Filtering
    - Removed objectionable images or texts.
    - Kept top 100 languages
- Learnings for our own dataset :
  - Process of crawling the dataset and applying the steps to filter.
  - WIT dataset ignores the discussions and comments, however, we are interested in them as they can be a conversation it itself.
    - This gives the cue to think around twitter or any publicly available platform which contains images, posts, replies and comments.
  - The paper has not outlined the filtering details as in how to extract the text which is relevant to the image or how to determine if some image should be removed.



